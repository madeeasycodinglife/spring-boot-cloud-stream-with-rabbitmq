https://www.vincenzoracca.com/en/blog/framework/spring/cloud-stream/

In this tutorial we will see how to easily create an event-driven application with Spring Cloud Stream and Kafka.

Components of Spring Cloud Stream

Spring Cloud Stream has three main components:

    Destination Binder: The component that provides integration with external message systems such as RabbitMQ or Kafka.
    Binding: A bridge between the external message system and the producers/consumers provided by the application.
    Message: The data structure used by producers/consumers to communicate with Destination Binders.

 let me draw a small image ::

                                   @Bean
                                   public Function<String,String> uppercase() {
   RabbitMQ ---> input binding            return String::toUpperCase;   output binding   ------->  Kafka
                                   }

From the image above you can see that the bindings are input and output. You can combine multiple binders;
for example you could read a message from RabbitMQ and write it to Kafka, creating a simple Java function (we will elaborate on this topic).


The developer will be able to focus solely on Business Logic in the form of functions, after which when choosing the message system to be
used, he will have to import the dependency of the chosen binder.

There are binders managed directly by Spring Cloud Stream such as Apache Kafka, RabbitMQ, Amazon Kinesis, and others managed by
external maintainers such as Azure EventHubs, Amazon SQS, etc. However, Spring Cloud Stream allows you to create custom binders.


Spring Cloud Stream from Spring Cloud Function ::

Spring Cloud Stream is based on Spring Cloud Function. Business logic can be written through simple functions.
The classic three interfaces of Java are used:

    Supplier: a function that has output but no input; it is also called producer, publisher, source .
    Consumer: a function that has input but no output, it is also called subscriber or sink.
    Function: a function that has both input and output, is also called processor.

And that is precisely why I am telling you about Spring Cloud Stream today. In previous versions,
there was no use of this approach, which made the framework less intuitive.


dependencies ::
  #1) RabbitMQ or Kafka
  #2) cloud stream
  #3) no need RabbitMQ or Kafka configuration i.e. in yml file i.e. for kafka no need serializers and deserializers or
  for RabbitMQ no need host, port, username, password, etc.
  #4) coding will be same only binder will be changed i.e. #1) cloud stream + #2) kafka or rabbitmq i.e. kafka will be replaced with
  rabbitmq and vice versa.

note :: if we use kafka then we don't need to write serializers and deserializers and for rabbitmq no need to add exchange,routing key,queue .
@Bean
public Supplier<SensorEventMessage> sensorEventProducer() {
    return () -> new SensorEventMessage("2", Instant.now(), 30.0);
}
That's it, we are done writing code! We do not need to write serializers and deserializers and for rabbitmq no need to add exchange,routing key,queue .
Everything is handled automatically by Spring Cloud Stream.


In fact, with Spring Cloud Stream, you can write code to produce/consume messages on Kafka,
but the same code would also work if you used RabbitMQ, AWS Kinesis, AWS SQS, Azure EventHubs, etc!

note::
  here in this application we use both supplied and consumer functions that's why in the same console we get the output

example of real time use cases of cloud stream ::
Sure! Here's a real-time use case of Spring Cloud Stream:

Imagine you're building an e-commerce application that consists of multiple microservices. One of these microservices is responsible for processing and fulfilling 
orders. Let's call it the Order Service.

In this scenario, you can utilize Spring Cloud Stream to handle the communication between the Order Service and other microservices involved in the order 
fulfillment process.

Use case: Order Fulfillment with Spring Cloud Stream

1. Order Service (Producer):
   The Order Service receives new order requests from customers. When a new order is placed, the Order Service can publish an order event message onto an 
output channel using Spring Cloud Stream. This order event message contains all the necessary details of the order, such as the customer information, 
items ordered, and shipping address.

2. Inventory Service (Consumer):
   The Inventory Service is responsible for managing the available stock of products. It needs to be notified whenever a new order is placed so that it can
update the inventory accordingly. By subscribing to the Order Service's output channel through an input binding in Spring Cloud Stream, the Inventory Service
can receive the order event messages in real-time. It can then process the message, deduct the ordered items from the inventory, and update the stock levels.

3. Shipping Service (Consumer):
   The Shipping Service is responsible for shipping the products to customers. When a new order is placed, it needs to be informed so that it can initiate the 
shipping process. Similar to the Inventory Service, the Shipping Service can subscribe to the Order Service's output channel via an input binding. It will 
receive the order event messages and start the shipping process based on the information provided in the message.

By utilizing Spring Cloud Stream, the Order Service can publish order events onto the output channel, and the Inventory Service and Shipping Service can consume 
these events by subscribing to the same channel. This decouples the services, allowing them to independently scale and evolve. The communication is seamless, 
and updates are processed in real-time, ensuring a smooth order fulfillment process for customers.

Overall, Spring Cloud Stream simplifies the messaging and communication between microservices, making it a powerful tool for building scalable and event-driven
architectures in real-time use cases like order fulfillment, IoT data processing, real-time analytics, and more.
